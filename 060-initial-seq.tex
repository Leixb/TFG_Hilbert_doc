%! TEX root = **/010-main.tex
% vim: spell spelllang=en:

\section{Program structure}

Initially, all the program was to be implemented in pure \emph{Julia} since
there are libraries to interface with \emph{CUDA} \cite{noauthor_juliagpu_nodate}
that should be able to handle the tasks needed. However there were some
complications with the \emph{Nvidia} drivers and compiling the \emph{Julia}
\emph{CUDA} kernels and some features are not yet available in \emph{CUDA.jl}.

Therefore, the main program in \emph{CUDA} will be implemented in \emph{C}
and expose the relevant method through an \emph{ABI} (Application Binary Interface)
so that it can be compiled into a shared binary and interface with \emph{Julia}
or any other language capable of using \emph{C} shared libraries. With this approach
we can achieve seamless interoperation between \emph{CUDA} and \emph{Julia} while
having full control of how \emph{CUDA} kernels behave and manage the resources.
All the analysis on the data obtained from the \emph{CUDA} computation can then
be processed using all the available \emph{Julia} libraries offering great
flexibility.

The \emph{ABI} interface will be very simple, exposing a method to initialize the GPU
memory, and the various different kernels to compute the data and transfer the result to
\emph{Julia}. Since \emph{Julia} is able to use \emph{C} structures natively through
its \emph{C} interface there is no overhead when transferring data since pointers can be
shared \cite{noauthor_c_nodate} and all the memory management can be delegated
to \emph{C}.

% \begin{figure}[H]
%     \centering
% \begin{tikzpicture}[node distance=2.5cm,auto,>=latex']
%     \node[draw, circle] (C) at (0,0){C};

% \node [draw, right=1cm of C]  (gpu) {GPU};

% \node [draw, circle, left=1cm of C]  (julia) {Julia};

% \draw[-stealth] (julia.east) -- (C.west)
%     node[midway,above]{run};
% \draw[-stealth] (C.east) -- (gpu.west)
%     node[midway,above]{run kernel};

% \end{tikzpicture}
% \caption{ABI diagram}
% \end{figure}


\pagebreak
\section{Initial implementation}%
\label{sec:initial_implementation}

Before implementing the program in CUDA we first need to implement a sequential
version of the program. This sequential code allows easier debugging of the
implementation and provides a basis to compare the speedup obtained with CUDA.

The main steps that the program must perform are:

\begin{enumerate}
    \item Compute a trajectory starting at various different points.
    \item Determine if the trajectory is a limit cycle.
    \item Classify all the starting points into groups corresponding to
        the different limit cycles.
\end{enumerate}

The first two steps of computing the trajectory and determining if it is a
limit cycle will be parallelized using \emph{CUDA} and the last step of analysis
will be done using \emph{Julia}.

\subsection{Computing the trajectory}

To compute the trajectory, a numerical method to integrate an ODE must be used.
There are various methods that can be used with varying complexity. In the
program we implemented \emph{Runge-Kutta} methods of different order (1, 2, (2)3, 4 and
4(5)) \cite{butcher_numerical_2008}. Two of these methods allow for adaptive
time stepping ((2)3 and 4(5)) meaning that they adjust the time steps ($h$)
according to the error tolerance.

There is no need to save all the trajectory to detect the cycles since the
relevant metrics can be computed as the integration step is happening.
This reduces not only the amount of memory needed to compute and store the
results but also allows the early termination of a trajectory computation if
we detect that it is a cycle, point or it goes out of bounds before the last
step is reached.

In~\cref{sec:metrics} there is an in-depth discussion of the metrics used and
how they are used to find limit cycle candidates. For the moment the relevant
point is that for each trajectory we only need to compute 2 \emph{loops} and
measure the ratio between the maximum and minimum points of each loop. If this
ratio is equal to 1 (within a tolerance margin), the trajectory is a cycle.



\paragraph{Julia}
For the very first prototyping, the various methods where implemented in \emph{Julia}
to check the correctness of the algorithm and then manually translated into \emph{C}
and checked again.

\paragraph{C translation}

In \cref{lst:julia_rk4,lst:c_rk4} we can
see the main RK4 routine implemented in \emph{Julia} and the corresponding
\emph{C} translation. Both versions of all methods were tested to ensure that they
where properly implemented (In~\cref{sec:convergence} there is a detail comparison of
the accuracy of the methods).

% Julia -> C


\begin{listing}[H]
    \caption{Julia version of RK4 step}
    \label{lst:julia_rk4}
\begin{minted}{julia}
function RK4(f::Function, x, y, h)
    xk1, yk1 = h.*f(x, y)
    xk2, yk2 = h.*f(x + xk1/2, y + yk1/2)
    xk3, yk3 = h.*f(x + xk2/2, y + yk2/2)
    xk4, yk4 = h.*f(x + xk3, y + yk3)

    x = x + (xk1 + 2xk2 + 2xk3 + xk4)/6
    y = y + (yk1 + 2yk2 + 2yk3 + yk4)/6

    x, y
end
\end{minted}
\end{listing}

\begin{listing}[H]
    \caption{C version of RK4}
    \label{lst:c_rk4}
\begin{minted}{c}
void rk4_step(const double x0, const double y0, double *const x1, double *const y1, const double h, double *const cache) {
    // xk1, yk1 = h.*f(x, y)
    f(x0, y0, h, &cache[0*2 + 0], &cache[0*2 + 1]);

    // xk2, yk2 = h.*f(x + xk1/2, y + yk1/2)
    *x1 = x0 + cache[0*2 + 0]/2.0;
    *y1 = y0 + cache[0*2 + 1]/2.0;
    f(*x1, *y1, h, &cache[1*2 + 0], &cache[1*2 + 1]);

    // xk3, yk3 = h.*f(x + xk2/2, y + yk2/2)
    *x1 = x0 + cache[1*2 + 0]/2.0;
    *y1 = y0 + cache[1*2 + 1]/2.0;
    f(*x1, *y1, h, &cache[2*2 + 0], &cache[2*2 + 1]);

    // xk4, yk4 = h.*f(x + xk3, y + yk3)
    *x1 = x0 + cache[2*2 + 0];
    *y1 = y0 + cache[2*2 + 1];
    f(*x1, *y1, h, &cache[3*2 + 0], &cache[3*2 + 1]);

    // x = x + (xk1 + 2xk2 + 2xk3 + xk4)/6
    // y = y + (yk1 + 2yk2 + 2yk3 + yk4)/6
    *x1 = x0 + (cache[0*2 + 0] + 2*cache[1*2 + 0] + 2*cache[2*2 + 0] + cache[3*2 + 0])/6.0;
    *y1 = y0 + (cache[0*2 + 1] + 2*cache[1*2 + 1] + 2*cache[2*2 + 1] + cache[3*2 + 1])/6.0;
}
\end{minted}
\end{listing}

% Sample code
