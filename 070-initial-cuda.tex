%! TEX root = **/010-main.tex
% vim: spell spelllang=en:

\section{CUDA implementation}

The C implementation was adapted to be run by CUDA. Each CUDA thread computes a full trajectory to completion and threads run in parallel as long as we do not
exceed the GPU threads. For the initial version we implemented the program to run in a single GPU with a total of 10240 CUDA cores and 12Gb of memory
\footnote{Details on the GPU hardware can be found in~\cref{lst:gpu_info} in the appendix}

Given the results of the convergence analysis from~\cref{sec:convergence}, each
trajectory was computed using RK4 with a step of $\Delta t=10^{-3}$ performing
$10^4$ steps. To save the full trajectory we need $10^4\cdot 8$ bytes (80kb). To
compute 10240 trajectories the total amount of memory needed is around 800Mb
which is feasible. However, we can compute the different metrics to find limit
cycles in place during the integration steps, so there is no need to save the
full trajectory (we can just save 8 to 100 bytes of data for each trajectory
depending on the metrics we compute).

Given a pair of axis (delimited $x$ and $y$ ranges) the different points in the
grid were separated into blocks of 32 by 32 points (1024 threads) and ran using
a CUDA kernel that computed the different values wanted for each trajectory. For
simplicity, the divisions performed on each axis where equal
for $x$ and $y$.

Although we have no problems on the amount of memory needed to save the
information needed, there are limitations in the number of register variables
available to each block (group of threads). If too many variables are needed to
perform the computation, they can cause a runtime error and the variables will
need to be moved to the heap (\emph{spilled}) or the threads will have to be
reduced. If using The maximum number of registers per block, the threads have a
maximum of 75 registers. The most complex kernel implemented used 54 registers
but when combined with rk45 stepping there were variables \emph{spilled} into
the shared memory. For this reason, the \emph{Runge Kutta} of oder 3 without adaptive
stepping was used by default. The results where similar with a reduced execution time
and less memory usage.
